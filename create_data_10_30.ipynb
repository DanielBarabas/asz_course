{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b25f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Try SciPy for stable Φ/Φ^{-1}; fall back to numpy/erf if not present.\n",
    "try:\n",
    "    from scipy.stats import norm\n",
    "    def phi(z): return norm.cdf(z)\n",
    "    def phi_inv(u): return norm.ppf(np.clip(u, 1e-12, 1-1e-12))\n",
    "    HAS_SCIPY = True\n",
    "except Exception:\n",
    "    from math import erf, sqrt\n",
    "    def phi(z): return 0.5 * (1.0 + erf(z / sqrt(2.0)))\n",
    "    # Simple, decent inverse via erfinv if available\n",
    "    try:\n",
    "        from scipy.special import erfinv\n",
    "        def phi_inv(u):\n",
    "            u = np.clip(u, 1e-12, 1-1e-12)\n",
    "            return sqrt(2.0)*erfinv(2*u - 1)\n",
    "    except Exception:\n",
    "        raise ImportError(\"This notebook prefers SciPy. Please `pip install scipy` for norm.ppf.\")\n",
    "\n",
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "# Paths (use your actual export locations)\n",
    "CONT_PATH = \"data/input/simple_params_1030/cs_2019_continuous_by_nace2.csv\"\n",
    "CORR_PATH = \"data/input/simple_params_1030/cs_2019_corr_long_by_nace2.csv\"\n",
    "\n",
    "# How many firms to simulate per NACE2?\n",
    "# We'll match the max 'N' reported across continuous vars for that NACE2 (below).\n",
    "SIM_SCALE = 1.0  # 1.0 = match counts; e.g. 0.5 = half, 2.0 = double\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9824581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = pd.read_csv(CONT_PATH)\n",
    "corr_long = pd.read_csv(CORR_PATH)\n",
    "\n",
    "# Clean column names we’ll use\n",
    "cont.columns = [c.strip() for c in cont.columns]\n",
    "corr_long.columns = [c.strip() for c in corr_long.columns]\n",
    "\n",
    "# Percentile columns available in your export\n",
    "pct_cols = [\"p0001\",\"p01\",\"p05\",\"p10\",\"p25\",\"p50\",\"p75\",\"p90\",\"p95\",\"p99\",\"p999\"]\n",
    "base_cols = [\"nace2\",\"var\",\"N\",\"min\",\"max\",\"median\",\"mean\",\"sd\",\"skewness\",\"excess_kurtosis\"]\n",
    "assert all(pc in cont.columns for pc in pct_cols), \"Some percentile columns missing.\"\n",
    "\n",
    "# Build a quick lookup of group sizes per NACE2\n",
    "N_by_nace = cont.groupby(\"nace2\")[\"N\"].max().astype(int)\n",
    "nace_list = list(N_by_nace.index)\n",
    "\n",
    "# Continuous variables present (union over all groups)\n",
    "all_vars = cont[\"var\"].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fedfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each (nace2, var) we’ll store U-grid and X-grid in dicts\n",
    "inv_grids = {}  # key: (nace2, var) → dict with 'u' and 'x' numpy arrays\n",
    "\n",
    "# Probability grid that matches the columns we have, plus endpoints\n",
    "u_grid = np.array([0.0,   0.001, 0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99, 0.999, 1.0])\n",
    "\n",
    "for g in nace_list:\n",
    "    sub = cont[cont[\"nace2\"] == g]\n",
    "    for v in sub[\"var\"].unique():\n",
    "        row = sub[sub[\"var\"] == v].iloc[0]\n",
    "        # Build X-grid in the same order as u_grid\n",
    "        x_vals = [\n",
    "            row[\"min\"],\n",
    "            row[\"p0001\"], row[\"p01\"], row[\"p05\"], row[\"p10\"], row[\"p25\"],\n",
    "            row[\"p50\"], row[\"p75\"], row[\"p90\"], row[\"p95\"], row[\"p99\"], row[\"p999\"],\n",
    "            row[\"max\"],\n",
    "        ]\n",
    "        x_grid = np.asarray(x_vals, dtype=float)\n",
    "\n",
    "        # Ensure monotonicity (just in case of minor rounding noise)\n",
    "        x_grid = np.maximum.accumulate(x_grid)\n",
    "\n",
    "        inv_grids[(g, v)] = {\"u\": u_grid, \"x\": x_grid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38667a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_psd_corr_for_group(g, var_list):\n",
    "    # Take rows for this nace2\n",
    "    g_corr = corr_long[corr_long[\"nace2\"] == g].copy()\n",
    "    # Ensure we only include requested var_list\n",
    "    g_corr = g_corr[g_corr[\"var1\"].isin(var_list) & g_corr[\"var2\"].isin(var_list)]\n",
    "    # Wide matrix\n",
    "    corr = pd.pivot_table(g_corr, index=\"var1\", columns=\"var2\", values=\"cor\")\n",
    "    # Reindex to full var_list on both axes\n",
    "    corr = corr.reindex(index=var_list, columns=var_list)\n",
    "    # Fill diag with 1, off-diag missing with 0\n",
    "    np.fill_diagonal(corr.values, 1.0)\n",
    "    corr = corr.fillna(0.0)\n",
    "\n",
    "    # Symmetrize\n",
    "    M = corr.values\n",
    "    M = 0.5 * (M + M.T)\n",
    "\n",
    "    # Eigenvalue clipping to ensure PSD\n",
    "    w, V = np.linalg.eigh(M)\n",
    "    w_clipped = np.clip(w, 1e-8, None)\n",
    "    M_psd = (V * w_clipped) @ V.T\n",
    "\n",
    "    # Normalize back to correlation (set diag = 1 and rescale slight drift)\n",
    "    d = np.sqrt(np.diag(M_psd))\n",
    "    M_psd = M_psd / np.outer(d, d)\n",
    "    np.fill_diagonal(M_psd, 1.0)\n",
    "\n",
    "    return pd.DataFrame(M_psd, index=var_list, columns=var_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a21caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nace2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "row_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tanass_clean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eszk",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sales_clean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pretax",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "persexp_clean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "satok",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "export_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ereduzem",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "emp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "liabilities",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b97ed54f-c582-46a8-8351-e4138f27f4b0",
       "rows": [
        [
         "0",
         "10",
         "0",
         "0.006363804489382258",
         "66772.59476024944",
         "29923.832264258537",
         "18529.912940835602",
         "-37.10427029641289",
         "94.33626409844159",
         "-9188.041831190923",
         "1180156.7316837017",
         "438.4224905019116",
         "0.0",
         "191021.7586237662"
        ],
        [
         "1",
         "10",
         "1",
         "25.299281267451654",
         "10151.716077661511",
         "78304.88678021004",
         "158273.63137351524",
         "12682.83845392355",
         "86948.0768919891",
         "8450.160706088434",
         "3265401.933283728",
         "22435.187059301665",
         "40.529525012577835",
         "37910.89683248847"
        ],
        [
         "2",
         "10",
         "2",
         "25.063239484003475",
         "151.0885616811365",
         "113422.62632481003",
         "786718.9130720028",
         "4273.047810645792",
         "60718.67137765306",
         "737127.7120291616",
         "45450773.463863984",
         "6657.828323978993",
         "21.728192539520634",
         "10879.315308242076"
        ],
        [
         "3",
         "10",
         "3",
         "1.4692062287713399",
         "107.77881042082699",
         "27571.399007266264",
         "69855.83915481433",
         "-187.0711262287327",
         "6329.708134640346",
         "18738.39127564327",
         "599694.1385196594",
         "-74.70653502597628",
         "8.954353740308429",
         "11129.220485473094"
        ],
        [
         "4",
         "10",
         "4",
         "10.689949696655265",
         "5465.810742831523",
         "250913.38658039784",
         "879128.6328200535",
         "8007.565265999332",
         "66960.18808141464",
         "152867.31447762647",
         "7389195.37963738",
         "15639.383139985925",
         "24.82691386346287",
         "98656.28529112975"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nace2</th>\n",
       "      <th>row_id</th>\n",
       "      <th>age</th>\n",
       "      <th>tanass_clean</th>\n",
       "      <th>eszk</th>\n",
       "      <th>sales_clean</th>\n",
       "      <th>pretax</th>\n",
       "      <th>persexp_clean</th>\n",
       "      <th>satok</th>\n",
       "      <th>export_value</th>\n",
       "      <th>ereduzem</th>\n",
       "      <th>emp</th>\n",
       "      <th>liabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>66772.594760</td>\n",
       "      <td>29923.832264</td>\n",
       "      <td>18529.912941</td>\n",
       "      <td>-37.104270</td>\n",
       "      <td>94.336264</td>\n",
       "      <td>-9188.041831</td>\n",
       "      <td>1.180157e+06</td>\n",
       "      <td>438.422491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>191021.758624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>25.299281</td>\n",
       "      <td>10151.716078</td>\n",
       "      <td>78304.886780</td>\n",
       "      <td>158273.631374</td>\n",
       "      <td>12682.838454</td>\n",
       "      <td>86948.076892</td>\n",
       "      <td>8450.160706</td>\n",
       "      <td>3.265402e+06</td>\n",
       "      <td>22435.187059</td>\n",
       "      <td>40.529525</td>\n",
       "      <td>37910.896832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>25.063239</td>\n",
       "      <td>151.088562</td>\n",
       "      <td>113422.626325</td>\n",
       "      <td>786718.913072</td>\n",
       "      <td>4273.047811</td>\n",
       "      <td>60718.671378</td>\n",
       "      <td>737127.712029</td>\n",
       "      <td>4.545077e+07</td>\n",
       "      <td>6657.828324</td>\n",
       "      <td>21.728193</td>\n",
       "      <td>10879.315308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.469206</td>\n",
       "      <td>107.778810</td>\n",
       "      <td>27571.399007</td>\n",
       "      <td>69855.839155</td>\n",
       "      <td>-187.071126</td>\n",
       "      <td>6329.708135</td>\n",
       "      <td>18738.391276</td>\n",
       "      <td>5.996941e+05</td>\n",
       "      <td>-74.706535</td>\n",
       "      <td>8.954354</td>\n",
       "      <td>11129.220485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10.689950</td>\n",
       "      <td>5465.810743</td>\n",
       "      <td>250913.386580</td>\n",
       "      <td>879128.632820</td>\n",
       "      <td>8007.565266</td>\n",
       "      <td>66960.188081</td>\n",
       "      <td>152867.314478</td>\n",
       "      <td>7.389195e+06</td>\n",
       "      <td>15639.383140</td>\n",
       "      <td>24.826914</td>\n",
       "      <td>98656.285291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nace2  row_id        age  tanass_clean           eszk    sales_clean  \\\n",
       "0    10       0   0.006364  66772.594760   29923.832264   18529.912941   \n",
       "1    10       1  25.299281  10151.716078   78304.886780  158273.631374   \n",
       "2    10       2  25.063239    151.088562  113422.626325  786718.913072   \n",
       "3    10       3   1.469206    107.778810   27571.399007   69855.839155   \n",
       "4    10       4  10.689950   5465.810743  250913.386580  879128.632820   \n",
       "\n",
       "         pretax  persexp_clean          satok  export_value      ereduzem  \\\n",
       "0    -37.104270      94.336264   -9188.041831  1.180157e+06    438.422491   \n",
       "1  12682.838454   86948.076892    8450.160706  3.265402e+06  22435.187059   \n",
       "2   4273.047811   60718.671378  737127.712029  4.545077e+07   6657.828324   \n",
       "3   -187.071126    6329.708135   18738.391276  5.996941e+05    -74.706535   \n",
       "4   8007.565266   66960.188081  152867.314478  7.389195e+06  15639.383140   \n",
       "\n",
       "         emp    liabilities  \n",
       "0   0.000000  191021.758624  \n",
       "1  40.529525   37910.896832  \n",
       "2  21.728193   10879.315308  \n",
       "3   8.954354   11129.220485  \n",
       "4  24.826914   98656.285291  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_blocks = []\n",
    "\n",
    "for g in nace_list:\n",
    "    # Variables with a marginal (grid) in this group:\n",
    "    vars_marg = cont.loc[cont[\"nace2\"] == g, \"var\"].unique().tolist()\n",
    "\n",
    "    # Variables present in correlation for this group:\n",
    "    g_vars_corr = pd.unique(\n",
    "        corr_long.loc[corr_long[\"nace2\"] == g, [\"var1\",\"var2\"]].values.ravel(\"K\")\n",
    "    ).tolist()\n",
    "\n",
    "    # Intersection = variables we'll simulate for this group\n",
    "    var_list = [v for v in all_vars if v in vars_marg and v in g_vars_corr]\n",
    "    if len(var_list) == 0:\n",
    "        continue\n",
    "\n",
    "    # Correlation matrix (PSD)\n",
    "    C = build_psd_corr_for_group(g, var_list).values\n",
    "\n",
    "    # Sample size for the group\n",
    "    N_sim = int(max(1, round(N_by_nace[g] * SIM_SCALE)))\n",
    "\n",
    "    # Draw correlated normals via eigen or cholesky\n",
    "    # Cholesky can occasionally fail if near-singular; use eigh instead\n",
    "    w, V = np.linalg.eigh(C)\n",
    "    w = np.clip(w, 0, None)\n",
    "    A = V @ np.diag(np.sqrt(w)) @ V.T\n",
    "\n",
    "    Z = rng.standard_normal(size=(N_sim, len(var_list)))\n",
    "    Z = Z @ A.T\n",
    "\n",
    "    # Map to uniforms\n",
    "    U = phi(Z)\n",
    "\n",
    "    # Map uniforms to each variable via its (nace2,var) inverse CDF grid\n",
    "    data = {}\n",
    "    for j, v in enumerate(var_list):\n",
    "        grid = inv_grids[(g, v)]\n",
    "        # linear interpolation on the grid\n",
    "        x_sim = np.interp(U[:, j], grid[\"u\"], grid[\"x\"])\n",
    "        data[v] = x_sim\n",
    "\n",
    "    block = pd.DataFrame(data)\n",
    "    block.insert(0, \"nace2\", g)\n",
    "    block.insert(1, \"row_id\", np.arange(N_sim, dtype=int))\n",
    "    synthetic_blocks.append(block)\n",
    "\n",
    "synthetic = pd.concat(synthetic_blocks, ignore_index=True)\n",
    "synthetic.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f01b7",
   "metadata": {},
   "source": [
    "print(\"Synthetic shape:\", synthetic.shape)\n",
    "print(\"Per NACE2 counts:\")\n",
    "print(synthetic[\"nace2\"].value_counts().sort_index())\n",
    "\n",
    "# Save\n",
    "Path(\"data/synthetic\").mkdir(parents=True, exist_ok=True)\n",
    "# synthetic.to_parquet(\"data/synthetic/sim_cs2019_by_nace2_gausscop.parquet\", index=False)\n",
    "# synthetic.to_csv(\"data/synthetic/sim_cs2019_by_nace2_gausscop.csv\", index=False)\n",
    "\n",
    "# Optional: a tiny sanity peek at means vs targets for one group/var\n",
    "g0 = synthetic[\"nace2\"].unique()[0]\n",
    "v0 = synthetic.columns[synthetic.columns.get_loc(\"row_id\")+1]  # first simulated var\n",
    "print(f\"\\nExample sanity — group {g0}, var {v0}\")\n",
    "print(\"simulated mean:\", synthetic.loc[synthetic[\"nace2\"]==g0, v0].mean())\n",
    "target_mean = cont.query(\"nace2 == @g0 and var == @v0\")[\"mean\"].iloc[0]\n",
    "print(\"target mean   :\", target_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d7bb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "dummy_path = \"data/input/simple_params_1030/cs_2019_dummy_shares_by_nace2.csv\"\n",
    "reg_path   = \"data/input/simple_params_1030/cs_2019_category_shares_by_nace2_region.csv\"\n",
    "cnty_path  = \"data/input/simple_params_1030/cs_2019_category_shares_by_nace2_county.csv\"\n",
    "own_path   = \"data/input/simple_params_1030/cs_2019_category_shares_by_nace2_owner.csv\"\n",
    "\n",
    "dshare = pd.read_csv(dummy_path)\n",
    "reg_sh = pd.read_csv(reg_path)   if Path(reg_path).exists()  else pd.DataFrame(columns=[\"nace2\",\"region\",\"N\",\"share\"])\n",
    "cnty_sh= pd.read_csv(cnty_path)  if Path(cnty_path).exists() else pd.DataFrame(columns=[\"nace2\",\"county\",\"N\",\"share\"])\n",
    "own_sh = pd.read_csv(own_path)   if Path(own_path).exists()  else pd.DataFrame(columns=[\"nace2\",\"firm_owner\",\"N\",\"share\"])\n",
    "\n",
    "# Keep only what we need\n",
    "dshare = dshare[[\"nace2\",\"share_export\",\"share_grant\",\"share_exit\"]].copy()\n",
    "\n",
    "# Make sure shares are within [0,1]\n",
    "for c in [\"share_export\",\"share_grant\",\"share_exit\"]:\n",
    "    if c in dshare.columns:\n",
    "        dshare[c] = dshare[c].clip(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919b4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = synthetic.copy()  # from your previous cells\n",
    "syn[\"has_export\"] = np.nan\n",
    "syn[\"has_grant\"]  = np.nan\n",
    "syn[\"exit\"]       = np.nan\n",
    "\n",
    "for g, gdf in syn.groupby(\"nace2\"):\n",
    "    idx = gdf.index\n",
    "    row = dshare[dshare[\"nace2\"] == g]\n",
    "    if row.empty:\n",
    "        # no shares for this group; skip\n",
    "        continue\n",
    "    p_export = float(row[\"share_export\"].iloc[0]) if \"share_export\" in row else 0.0\n",
    "    p_grant  = float(row[\"share_grant\"].iloc[0])  if \"share_grant\"  in row else 0.0\n",
    "    p_exit   = float(row[\"share_exit\"].iloc[0])   if \"share_exit\"   in row else 0.0\n",
    "\n",
    "    syn.loc[idx, \"has_export\"] = rng.binomial(1, p_export, size=len(idx))\n",
    "    syn.loc[idx, \"has_grant\"]  = rng.binomial(1, p_grant,  size=len(idx))\n",
    "    syn.loc[idx, \"exit\"]       = rng.binomial(1, p_exit,   size=len(idx))\n",
    "\n",
    "# Cast to integers\n",
    "syn[\"has_export\"] = syn[\"has_export\"].astype(\"Int64\")\n",
    "syn[\"has_grant\"]  = syn[\"has_grant\"].astype(\"Int64\")\n",
    "syn[\"exit\"]       = syn[\"exit\"].astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a006de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare containers\n",
    "syn[\"region\"]     = pd.NA\n",
    "syn[\"county\"]     = pd.NA\n",
    "syn[\"firm_owner\"] = pd.NA\n",
    "\n",
    "# Region\n",
    "if not reg_sh.empty:\n",
    "    reg_sh = reg_sh.rename(columns={reg_sh.columns[0]: \"region\"} if reg_sh.columns[0] != \"region\" else {})\n",
    "    # keep columns: nace2, region, share\n",
    "    keep_cols = [c for c in [\"nace2\",\"region\",\"share\"] if c in reg_sh.columns]\n",
    "    reg_sh = reg_sh[keep_cols].dropna(subset=[\"region\"]).copy()\n",
    "    # normalize shares per group (just in case)\n",
    "    reg_sh[\"share\"] = reg_sh[\"share\"].clip(lower=0)\n",
    "    reg_sh[\"share\"] = reg_sh.groupby(\"nace2\")[\"share\"].transform(lambda s: s / s.sum() if s.sum() > 0 else s)\n",
    "\n",
    "    for g, gdf in syn.groupby(\"nace2\"):\n",
    "        idx = gdf.index\n",
    "        opts = reg_sh[reg_sh[\"nace2\"] == g]\n",
    "        if opts.empty:\n",
    "            continue\n",
    "        cats = opts[\"region\"].astype(str).tolist()\n",
    "        probs= opts[\"share\"].astype(float).to_numpy()\n",
    "        # guard for rounding: re-normalize\n",
    "        probs = probs / probs.sum() if probs.sum() > 0 else np.ones_like(probs)/len(probs)\n",
    "        draws = rng.choice(cats, size=len(idx), p=probs, replace=True)\n",
    "        syn.loc[idx, \"region\"] = draws\n",
    "\n",
    "# County\n",
    "if not cnty_sh.empty:\n",
    "    cnty_sh = cnty_sh.rename(columns={cnty_sh.columns[0]: \"county\"} if cnty_sh.columns[0] != \"county\" else {})\n",
    "    keep_cols = [c for c in [\"nace2\",\"county\",\"share\"] if c in cnty_sh.columns]\n",
    "    cnty_sh = cnty_sh[keep_cols].dropna(subset=[\"county\"]).copy()\n",
    "    cnty_sh[\"share\"] = cnty_sh[\"share\"].clip(lower=0)\n",
    "    cnty_sh[\"share\"] = cnty_sh.groupby(\"nace2\")[\"share\"].transform(lambda s: s / s.sum() if s.sum() > 0 else s)\n",
    "\n",
    "    for g, gdf in syn.groupby(\"nace2\"):\n",
    "        idx = gdf.index\n",
    "        opts = cnty_sh[cnty_sh[\"nace2\"] == g]\n",
    "        if opts.empty:\n",
    "            continue\n",
    "        cats = opts[\"county\"].astype(str).tolist()\n",
    "        probs= opts[\"share\"].astype(float).to_numpy()\n",
    "        probs = probs / probs.sum() if probs.sum() > 0 else np.ones_like(probs)/len(probs)\n",
    "        draws = rng.choice(cats, size=len(idx), p=probs, replace=True)\n",
    "        syn.loc[idx, \"county\"] = draws\n",
    "\n",
    "# Firm owner\n",
    "if not own_sh.empty:\n",
    "    own_sh = own_sh.rename(columns={own_sh.columns[0]: \"firm_owner\"} if own_sh.columns[0] != \"firm_owner\" else {})\n",
    "    keep_cols = [c for c in [\"nace2\",\"firm_owner\",\"share\"] if c in own_sh.columns]\n",
    "    own_sh = own_sh[keep_cols].dropna(subset=[\"firm_owner\"]).copy()\n",
    "    own_sh[\"share\"] = own_sh[\"share\"].clip(lower=0)\n",
    "    own_sh[\"share\"] = own_sh.groupby(\"nace2\")[\"share\"].transform(lambda s: s / s.sum() if s.sum() > 0 else s)\n",
    "\n",
    "    for g, gdf in syn.groupby(\"nace2\"):\n",
    "        idx = gdf.index\n",
    "        opts = own_sh[own_sh[\"nace2\"] == g]\n",
    "        if opts.empty:\n",
    "            continue\n",
    "        cats = opts[\"firm_owner\"].astype(str).tolist()\n",
    "        probs= opts[\"share\"].astype(float).to_numpy()\n",
    "        probs = probs / probs.sum() if probs.sum() > 0 else np.ones_like(probs)/len(probs)\n",
    "        draws = rng.choice(cats, size=len(idx), p=probs, replace=True)\n",
    "        syn.loc[idx, \"firm_owner\"] = draws\n",
    "\n",
    "for col in [\"emp\", \"age\"]:\n",
    "    if col in syn.columns:\n",
    "        vals = pd.to_numeric(syn[col], errors=\"coerce\")          # ensure numeric\n",
    "        vals = np.rint(vals)                                     # round to nearest int\n",
    "        vals = np.clip(vals, 0, None)                            # no negatives\n",
    "        syn[col] = pd.Series(vals).astype(\"Int64\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63c5f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = pd.read_excel(\"data/nace2_labels.xlsx\")\n",
    "lab[\"nace2\"] = lab[\"nace2\"].apply(str)\n",
    "lab[\"nace2\"] = lab[\"nace2\"].str.extract(r\"(\\d+)\", expand=False).fillna(\"\").str.zfill(2).str[:2]\n",
    "\n",
    "syn = syn.merge(lab, on=\"nace2\", how=\"left\")\n",
    "syn[\"nace2_name_code\"] = syn[\"name_hu\"].fillna(\"NACE \" + syn[\"nace2\"]) + \" (\" + syn[\"nace2\"] + \")\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc1af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Simulate sales growth from estimated regression (insert before final export) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Files exported by your estimation step (edit if different)\n",
    "coef_by_industry_path = \"data/input/simple_params_1030/cs_2019_reg_growth_G2_coefs_by_nace2.csv\"\n",
    "coef_overall_path     = \"data/input/simple_params_1030/cs_2019_reg_growth_G2_coefs.csv\"\n",
    "\n",
    "# Fallback residual SD if not provided\n",
    "DEFAULT_SIGMA = 0.25\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Ensure needed columns / types\n",
    "df = syn.copy()\n",
    "if \"nace2\" in df.columns:\n",
    "    df[\"nace2\"] = df[\"nace2\"].astype(str)\n",
    "else:\n",
    "    raise ValueError(\"`nace2` column is required in df for per-industry growth simulation.\")\n",
    "\n",
    "if \"sales_clean\" not in df.columns:\n",
    "    raise ValueError(\"`sales_clean` column is missing from df.\")\n",
    "\n",
    "# Core regressor used in growth model (adjust/add others if your model has them)\n",
    "df[\"ln_sales\"] = np.log(np.clip(df[\"sales_clean\"].astype(float), 1e-9, None))\n",
    "\n",
    "# Load coefficients: prefer by-industry, else overall\n",
    "use_by_industry = Path(coef_by_industry_path).exists()\n",
    "if use_by_industry:\n",
    "    coefs_raw = pd.read_csv(coef_by_industry_path)\n",
    "    if not {\"nace2\",\"term\",\"estimate\"}.issubset(coefs_raw.columns):\n",
    "        raise ValueError(\"growth_lm_by_nace2.csv must have columns: nace2, term, estimate\")\n",
    "    # optional residual SD per industry\n",
    "    sig_by = (\n",
    "        coefs_raw.loc[coefs_raw[\"term\"]==\"__sigma__\", [\"nace2\",\"estimate\"]]\n",
    "        .rename(columns={\"estimate\":\"sigma\"})\n",
    "        .assign(nace2=lambda d: d[\"nace2\"].astype(str))\n",
    "    )\n",
    "    coefs = coefs_raw.loc[coefs_raw[\"term\"]!=\"__sigma__\", [\"nace2\",\"term\",\"estimate\"]].copy()\n",
    "else:\n",
    "    if not Path(coef_overall_path).exists():\n",
    "        raise FileNotFoundError(\"No growth coefficient file found. Expected one of:\\n\"\n",
    "                                f\"- {coef_by_industry_path}\\n- {coef_overall_path}\")\n",
    "    coefs_all = pd.read_csv(coef_overall_path)\n",
    "    if not {\"term\",\"estimate\"}.issubset(coefs_all.columns):\n",
    "        raise ValueError(\"growth_lm_overall.csv must have columns: term, estimate\")\n",
    "    sig_overall = coefs_all.loc[coefs_all[\"term\"]==\"__sigma__\", \"estimate\"]\n",
    "    sigma_overall = float(sig_overall.iloc[0]) if len(sig_overall)==1 else DEFAULT_SIGMA\n",
    "    coefs = coefs_all.loc[coefs_all[\"term\"]!=\"__sigma__\", [\"term\",\"estimate\"]].copy()\n",
    "\n",
    "# Build predicted growth g_hat = X beta (match terms by column names; intercept \"(Intercept)\" if present)\n",
    "g_hat = np.zeros(len(df), dtype=float)\n",
    "\n",
    "if use_by_industry:\n",
    "    # loop industries, apply their betas\n",
    "    for gcode, gcoefs in coefs.groupby(\"nace2\"):\n",
    "        mask = (df[\"nace2\"] == str(gcode)).values\n",
    "        if not mask.any():\n",
    "            continue\n",
    "        part = np.zeros(mask.sum(), dtype=float)\n",
    "        # intercept\n",
    "        if (gcoefs[\"term\"] == \"(Intercept)\").any():\n",
    "            b0 = float(gcoefs.loc[gcoefs[\"term\"]==\"(Intercept)\",\"estimate\"].iloc[0])\n",
    "            part += b0\n",
    "        # other terms\n",
    "        for _, r in gcoefs.iterrows():\n",
    "            term = r[\"term\"]\n",
    "            if term == \"(Intercept)\":\n",
    "                continue\n",
    "            beta = float(r[\"estimate\"])\n",
    "            if term in df.columns:\n",
    "                part += beta * df.loc[mask, term].astype(float).to_numpy()\n",
    "            # silently ignore missing terms -> contribute 0\n",
    "        g_hat[mask] = part\n",
    "\n",
    "    # residual SD per industry if provided; else default\n",
    "    if 'sig_by' in locals() and len(sig_by) > 0:\n",
    "        sigma_map = dict(zip(sig_by[\"nace2\"], sig_by[\"sigma\"]))\n",
    "        sigma_vec = np.array([sigma_map.get(str(c), DEFAULT_SIGMA) for c in df[\"nace2\"]], dtype=float)\n",
    "    else:\n",
    "        sigma_vec = np.full(len(df), DEFAULT_SIGMA, dtype=float)\n",
    "\n",
    "else:\n",
    "    # overall model\n",
    "    if (coefs[\"term\"] == \"(Intercept)\").any():\n",
    "        g_hat += float(coefs.loc[coefs[\"term\"]==\"(Intercept)\",\"estimate\"].iloc[0])\n",
    "    for _, r in coefs.iterrows():\n",
    "        term = r[\"term\"]\n",
    "        if term == \"(Intercept)\":\n",
    "            continue\n",
    "        beta = float(r[\"estimate\"])\n",
    "        if term in df.columns:\n",
    "            g_hat += beta * df[term].astype(float).to_numpy()\n",
    "    sigma_vec = np.full(len(df), sigma_overall, dtype=float)\n",
    "\n",
    "# Simulate growth and implied next-period sales\n",
    "eps = rng.normal(loc=0.0, scale=sigma_vec, size=len(df))\n",
    "df[\"growth_sim\"] = g_hat + eps                               # ln(S_{t+1}) - ln(S_t)\n",
    "df[\"ln_sales_lead_sim\"] = df[\"ln_sales\"] + df[\"growth_sim\"]  # ln S_{t+1}\n",
    "df[\"sales_lead_sim\"]    = np.exp(df[\"ln_sales_lead_sim\"])    # S_{t+1}\n",
    "\n",
    "# (Optional) keep integers for count-like vars\n",
    "if \"emp\" in df.columns:\n",
    "    df[\"emp\"] = pd.to_numeric(df[\"emp\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "if \"age\" in df.columns:\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "\n",
    "# --- continue with your existing export right after this cell ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "018d80c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales_clean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sales_lead_sim",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ad2007ac-8105-4643-82cd-c47562906361",
       "rows": [
        [
         "0",
         "18529.912940835602",
         "19641.117992841268"
        ],
        [
         "1",
         "158273.63137351524",
         "33006.79653060198"
        ],
        [
         "2",
         "786718.9130720028",
         "97877.14450588824"
        ],
        [
         "3",
         "69855.83915481433",
         "39084.58556799454"
        ],
        [
         "4",
         "879128.6328200535",
         "52071.882860261496"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_clean</th>\n",
       "      <th>sales_lead_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18529.912941</td>\n",
       "      <td>19641.117993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158273.631374</td>\n",
       "      <td>33006.796531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>786718.913072</td>\n",
       "      <td>97877.144506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69855.839155</td>\n",
       "      <td>39084.585568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>879128.632820</td>\n",
       "      <td>52071.882860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sales_clean  sales_lead_sim\n",
       "0   18529.912941    19641.117993\n",
       "1  158273.631374    33006.796531\n",
       "2  786718.913072    97877.144506\n",
       "3   69855.839155    39084.585568\n",
       "4  879128.632820    52071.882860"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn = df\n",
    "syn[[\"sales_clean\",\"sales_lead_sim\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d0fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "county_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "county",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "de2f95d3-ff88-48ad-a90f-a012beec70e0",
       "rows": [
        [
         "0",
         "Budapest",
         "1"
        ],
        [
         "1",
         "Baranya",
         "2"
        ],
        [
         "2",
         "Bács-Kiskun",
         "3"
        ],
        [
         "3",
         "Békés",
         "4"
        ],
        [
         "4",
         "Borsod-Abaúj-Zemplén",
         "5"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budapest</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baranya</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bács-Kiskun</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Békés</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Borsod-Abaúj-Zemplén</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            county_name  county\n",
       "0              Budapest       1\n",
       "1               Baranya       2\n",
       "2           Bács-Kiskun       3\n",
       "3                 Békés       4\n",
       "4  Borsod-Abaúj-Zemplén       5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_name_correspondances = pd.read_excel(\"data/county_names_codes.xlsx\")\n",
    "county_name_correspondances = county_name_correspondances.rename(columns={\"CODE\":\"county\",\"NAME\":\"county_name\"})\n",
    "county_name_correspondances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1be2b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn[\"county\"] = syn[\"county\"].astype(\"float\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7498a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = syn.merge(county_name_correspondances,how=\"left\",on=\"county\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d8612cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "REL_OUT_COL = \"sales_growth_perc\"\n",
    "LOG_OUT_COL = \"sales_growth_log_diff\"\n",
    "\n",
    "def add_outcomes(d: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds two outcome columns to `d`:\n",
    "      - y_rel_growth = (sales_lead - sales) / sales\n",
    "      - y_log_growth = ln(sales_lead) - ln(sales)\n",
    "    Uses fallbacks matching the app's current logic.\n",
    "    \"\"\"\n",
    "    d = d.copy()\n",
    "\n",
    "    # Base variables (primary + fallbacks)\n",
    "    sales = d[\"sales_clean\"] if \"sales_clean\" in d.columns else None\n",
    "    sales_lead = (\n",
    "        d[\"sales_lead_sim\"] if \"sales_lead_sim\" in d.columns\n",
    "        else d[\"sales22_lead2\"] if \"sales22_lead2\" in d.columns\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    ln_sales = d[\"ln_sales\"] if \"ln_sales\" in d.columns else None\n",
    "    ln_sales_lead = (\n",
    "        d[\"ln_sales_lead_sim\"] if \"ln_sales_lead_sim\" in d.columns\n",
    "        else d[\"ln_sales22_lead2\"] if \"ln_sales22_lead2\" in d.columns\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # --- Relative growth ------------------------------------------------------\n",
    "    rel = pd.Series(np.nan, index=d.index, dtype=\"float64\")\n",
    "    if sales is not None and sales_lead is not None:\n",
    "        base = sales.astype(float)\n",
    "        lead = sales_lead.astype(float)\n",
    "        denom = np.where(base != 0, base, np.nan)\n",
    "        rel = (lead - base) / denom\n",
    "    d[REL_OUT_COL] = rel\n",
    "\n",
    "    # --- Log growth -----------------------------------------------------------\n",
    "    logg = pd.Series(np.nan, index=d.index, dtype=\"float64\")\n",
    "    if ln_sales is None and sales is not None:\n",
    "        # backfill ln_sales from sales\n",
    "        ln_sales = np.log(np.clip(sales.astype(float), 1e-9, None))\n",
    "    if ln_sales is not None and ln_sales_lead is not None:\n",
    "        logg = ln_sales_lead.astype(float) - ln_sales.astype(float)\n",
    "    d[LOG_OUT_COL] = logg\n",
    "\n",
    "    # Optional: record provenance for debugging\n",
    "    d.attrs[\"outcome_sources\"] = {\n",
    "        \"rel\": {\n",
    "            \"sales\": \"sales_clean\" if sales is not None else None,\n",
    "            \"lead\": (\"sales_lead_sim\" if \"sales_lead_sim\" in d.columns\n",
    "                     else \"sales22_lead2\" if \"sales22_lead2\" in d.columns\n",
    "                     else None),\n",
    "        },\n",
    "        \"log\": {\n",
    "            \"ln_sales\": \"ln_sales\" if \"ln_sales\" in d.columns else \"(from sales_clean)\",\n",
    "            \"ln_lead\": (\"ln_sales_lead_sim\" if \"ln_sales_lead_sim\" in d.columns\n",
    "                        else \"ln_sales22_lead2\" if \"ln_sales22_lead2\" in d.columns\n",
    "                        else None),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd09d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = add_outcomes(syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0925dfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sales_growth_perc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ce39bcc7-28cb-4374-bfe4-b0e6ec761adf",
       "rows": [
        [
         "0",
         "0.05996817446221396"
        ],
        [
         "1",
         "-0.7914573877899589"
        ],
        [
         "2",
         "-0.8755881638542352"
        ],
        [
         "3",
         "-0.4404965133784252"
        ],
        [
         "4",
         "-0.9407687556561248"
        ],
        [
         "5",
         "9.481461693268297"
        ],
        [
         "6",
         "9.003257716008457"
        ],
        [
         "7",
         "4.873414636957109"
        ],
        [
         "8",
         "-0.7146786270551976"
        ],
        [
         "9",
         "3.2847954307000493"
        ],
        [
         "10",
         "-0.9347001441374656"
        ],
        [
         "11",
         "5.124483565436772"
        ],
        [
         "12",
         "29.070014785519934"
        ],
        [
         "13",
         "-0.011099735963842328"
        ],
        [
         "14",
         "18.889325152769704"
        ],
        [
         "15",
         "-0.9470223943986322"
        ],
        [
         "16",
         "-0.542704980600648"
        ],
        [
         "17",
         "-0.6348336128965582"
        ],
        [
         "18",
         "0.27259198038474186"
        ],
        [
         "19",
         "10.220310674351719"
        ],
        [
         "20",
         "-0.2315216107531797"
        ],
        [
         "21",
         "-0.9730241995160943"
        ],
        [
         "22",
         "-0.8514875335312423"
        ],
        [
         "23",
         "30.017298968274346"
        ],
        [
         "24",
         "-0.8795086253028146"
        ],
        [
         "25",
         "-0.6632817348719603"
        ],
        [
         "26",
         null
        ],
        [
         "27",
         "0.5104708332391061"
        ],
        [
         "28",
         null
        ],
        [
         "29",
         "-0.27607613738686554"
        ],
        [
         "30",
         "-0.7268249403113918"
        ],
        [
         "31",
         "-0.7559636445979782"
        ],
        [
         "32",
         "-0.6759443260086871"
        ],
        [
         "33",
         "-0.2909818448917964"
        ],
        [
         "34",
         null
        ],
        [
         "35",
         "-0.7989185874448232"
        ],
        [
         "36",
         "-0.707830613711401"
        ],
        [
         "37",
         null
        ],
        [
         "38",
         "-0.7752681901455569"
        ],
        [
         "39",
         "-0.5958837379392327"
        ],
        [
         "40",
         "-0.559756979016854"
        ],
        [
         "41",
         "-0.5754842682303318"
        ],
        [
         "42",
         "-0.7670176716052369"
        ],
        [
         "43",
         "6.709417102658908"
        ],
        [
         "44",
         "-0.6087583124298752"
        ],
        [
         "45",
         "-0.9484691929469425"
        ],
        [
         "46",
         "0.16389418934456648"
        ],
        [
         "47",
         "7.882632845218566"
        ],
        [
         "48",
         "20.951021649992658"
        ],
        [
         "49",
         "7.251241460968312"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 829836
       }
      },
      "text/plain": [
       "0         0.059968\n",
       "1        -0.791457\n",
       "2        -0.875588\n",
       "3        -0.440497\n",
       "4        -0.940769\n",
       "            ...   \n",
       "829831   -0.575403\n",
       "829832    0.034945\n",
       "829833    0.629922\n",
       "829834    0.222610\n",
       "829835   -0.494517\n",
       "Name: sales_growth_perc, Length: 829836, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn[\"sales_growth_perc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16587f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic with dummies + categoricals: (414918, 28)\n",
      "nace2             object\n",
      "row_id             int64\n",
      "age                Int64\n",
      "tanass_clean     float64\n",
      "eszk             float64\n",
      "sales_clean      float64\n",
      "pretax           float64\n",
      "persexp_clean    float64\n",
      "satok            float64\n",
      "export_value     float64\n",
      "ereduzem         float64\n",
      "emp                Int64\n",
      "dtype: object\n",
      "\n",
      "Example shares — group 10\n",
      "export 0.06861198738170347 grant 0.03680336487907466 exit 0.11277602523659307\n"
     ]
    }
   ],
   "source": [
    "syn = syn[syn[\"nace2\"] != \"ALL\"]\n",
    "print(\"Synthetic with dummies + categoricals:\", syn.shape)\n",
    "print(syn.dtypes.head(12))\n",
    "\n",
    "# Quick share checks (simulated vs target) for one group\n",
    "g0 = syn[\"nace2\"].unique()[0]\n",
    "print(\"\\nExample shares — group\", g0)\n",
    "sim_row = syn[syn[\"nace2\"]==g0]\n",
    "print(\"export\", sim_row[\"has_export\"].mean(), \n",
    "      \"grant\", sim_row[\"has_grant\"].mean(), \n",
    "      \"exit\",  sim_row[\"exit\"].mean())\n",
    "\n",
    "# Save\n",
    "Path(\"data/synthetic\").mkdir(parents=True, exist_ok=True)\n",
    "syn.to_parquet(\"data/synthetic/sim_cs2019_by_nace2_withcats.parquet\", index=False)\n",
    "# syn.to_csv(\"data/synthetic/sim_cs2019_by_nace2_withcats.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de06e846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "nace2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ebb5a4dc-bb6e-4d14-a07f-acd9a09a9fc9",
       "rows": [
        [
         "47",
         "44539"
        ],
        [
         "68",
         "36993"
        ],
        [
         "46",
         "30452"
        ],
        [
         "43",
         "21576"
        ],
        [
         "70",
         "19131"
        ],
        [
         "45",
         "16616"
        ],
        [
         "41",
         "16127"
        ],
        [
         "56",
         "15883"
        ],
        [
         "86",
         "15840"
        ],
        [
         "71",
         "15412"
        ],
        [
         "69",
         "14882"
        ],
        [
         "62",
         "13468"
        ],
        [
         "49",
         "9831"
        ],
        [
         "85",
         "7834"
        ],
        [
         "82",
         "7678"
        ],
        [
         "74",
         "6630"
        ],
        [
         "25",
         "6511"
        ],
        [
         "66",
         "5922"
        ],
        [
         "11",
         "5881"
        ],
        [
         "81",
         "5568"
        ],
        [
         "96",
         "5003"
        ],
        [
         "73",
         "4991"
        ],
        [
         "42",
         "3997"
        ],
        [
         "55",
         "3968"
        ],
        [
         "16",
         "3814"
        ],
        [
         "10",
         "3804"
        ],
        [
         "93",
         "3694"
        ],
        [
         "90",
         "3610"
        ],
        [
         "64",
         "3584"
        ],
        [
         "63",
         "3470"
        ],
        [
         "77",
         "3365"
        ],
        [
         "52",
         "3319"
        ],
        [
         "14",
         "3239"
        ],
        [
         "72",
         "3067"
        ],
        [
         "58",
         "2966"
        ],
        [
         "59",
         "2960"
        ],
        [
         "33",
         "2675"
        ],
        [
         "80",
         "2435"
        ],
        [
         "18",
         "2348"
        ],
        [
         "28",
         "2227"
        ],
        [
         "22",
         "2214"
        ],
        [
         "35",
         "2196"
        ],
        [
         "31",
         "1882"
        ],
        [
         "32",
         "1869"
        ],
        [
         "95",
         "1839"
        ],
        [
         "79",
         "1488"
        ],
        [
         "23",
         "1466"
        ],
        [
         "26",
         "1292"
        ],
        [
         "78",
         "1259"
        ],
        [
         "21",
         "1141"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 84
       }
      },
      "text/plain": [
       "nace2\n",
       "47    44539\n",
       "68    36993\n",
       "46    30452\n",
       "43    21576\n",
       "70    19131\n",
       "      ...  \n",
       "98        6\n",
       "34        3\n",
       "76        2\n",
       "57        1\n",
       "67        1\n",
       "Name: count, Length: 84, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn[\"nace2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "250f2ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "nace2_name_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "59b25a93-af72-4b97-b6d2-5ae2db353c01",
       "rows": [
        [
         "Kiskereskedelem (kivéve: gépjármű, motorkerékpár) (47)",
         "44539"
        ],
        [
         "INGATLANÜGYLETEK (68)",
         "36993"
        ],
        [
         "Nagykereskedelem (kivéve: jármű, motorkerékpár) (46)",
         "30452"
        ],
        [
         "Speciális szaképítés (43)",
         "21576"
        ],
        [
         "Üzletvezetési, vezetői tanácsadás (70)",
         "19131"
        ],
        [
         "Gépjármű, motorkerékpár kereskedelme, javítása (45)",
         "16616"
        ],
        [
         "Épületek építése (41)",
         "16127"
        ],
        [
         "Vendéglátás (56)",
         "15883"
        ],
        [
         "Humán-egészségügyi ellátás (86)",
         "15840"
        ],
        [
         "Mérnöki és építészmérnöki tevékenység; műszaki vizsgálat, elemzés (71)",
         "15412"
        ],
        [
         "Jogi, számviteli, adószakértői tevékenység (69)",
         "14882"
        ],
        [
         "Információ-technológiai szolgáltatás (62)",
         "13468"
        ],
        [
         "Szárazföldi, csővezetékes szállítás (49)",
         "9831"
        ],
        [
         "Oktatás (85)",
         "7834"
        ],
        [
         "Adminisztratív, kiegészítő egyéb üzleti szolgáltatás (82)",
         "7678"
        ],
        [
         "Egyéb szakmai, tudományos, műszaki tevékenység (74)",
         "6630"
        ],
        [
         "Fémfeldolgozási termék gyártása (25)",
         "6511"
        ],
        [
         "Egyéb pénzügyi tevékenység (66)",
         "5922"
        ],
        [
         "Italgyártás (11)",
         "5881"
        ],
        [
         "Építményüzemeltetés, zöldterület-kezelés (81)",
         "5568"
        ],
        [
         "Egyéb személyi szolgáltatás (96)",
         "5003"
        ],
        [
         "Reklám, piackutatás (73)",
         "4991"
        ],
        [
         "Egyéb építmény építése (42)",
         "3997"
        ],
        [
         "Szálláshely-szolgáltatás (55)",
         "3968"
        ],
        [
         "Fafeldolgozás (kivéve: bútor), fonottáru gyártása (16)",
         "3814"
        ],
        [
         "Élelmiszergyártás (10)",
         "3804"
        ],
        [
         "Sport-, szórakoztató, szabadidős tevékenység (93)",
         "3694"
        ],
        [
         "Alkotó-, művészeti, szórakoztató tevékenység (90)",
         "3610"
        ],
        [
         "Pénzügyi közvetítés (kivéve: biztosítási, nyugdíjpénztári tevékenység) (64)",
         "3584"
        ],
        [
         "Információs szolgáltatás (63)",
         "3470"
        ],
        [
         "Kölcsönzés, operatív lízing (77)",
         "3365"
        ],
        [
         "Raktározás, szállítást kiegészítő tevékenység (52)",
         "3319"
        ],
        [
         "Ruházati termék gyártása (14)",
         "3239"
        ],
        [
         "Tudományos kutatás, fejlesztés (72)",
         "3067"
        ],
        [
         "Kiadói tevékenység (58)",
         "2966"
        ],
        [
         "Film, video, televízióműsor gyártása, hangfelvétel-kiadás (59)",
         "2960"
        ],
        [
         "Ipari gép, berendezés, eszköz javítása, üzembe helyezése (33)",
         "2675"
        ],
        [
         "Biztonsági, nyomozói tevékenység (80)",
         "2435"
        ],
        [
         "Nyomdai és egyéb sokszorosítási tevékenység (18)",
         "2348"
        ],
        [
         "Gép, gépi berendezés gyártása (28)",
         "2227"
        ],
        [
         "Gumi-, műanyag termék gyártása (22)",
         "2214"
        ],
        [
         "Villamosenergia-, gáz-, gőzellátás, légkondicionálás (35)",
         "2196"
        ],
        [
         "Bútorgyártás (31)",
         "1882"
        ],
        [
         "Egyéb feldolgozóipari tevékenység (32)",
         "1869"
        ],
        [
         "Számítógép, személyi, háztartási cikk javítása (95)",
         "1839"
        ],
        [
         "Utazásközvetítés, utazásszervezés, egyéb foglalás (79)",
         "1488"
        ],
        [
         "Nemfém ásványi termék gyártása (23)",
         "1466"
        ],
        [
         "Számítógép, elektronikai, optikai termék gyártása (26)",
         "1292"
        ],
        [
         "Munkaerőpiaci szolgáltatás (78)",
         "1259"
        ],
        [
         "Gyógyszergyártás (21)",
         "1141"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 84
       }
      },
      "text/plain": [
       "nace2_name_code\n",
       "Kiskereskedelem (kivéve: gépjármű, motorkerékpár) (47)                 44539\n",
       "INGATLANÜGYLETEK (68)                                                  36993\n",
       "Nagykereskedelem (kivéve: jármű, motorkerékpár) (46)                   30452\n",
       "Speciális szaképítés (43)                                              21576\n",
       "Üzletvezetési, vezetői tanácsadás (70)                                 19131\n",
       "                                                                       ...  \n",
       "Háztartás termék-előállítása, szolgáltatása saját fogyasztásra (98)        6\n",
       "NACE 34 (34)                                                               3\n",
       "NACE 76 (76)                                                               2\n",
       "NACE 57 (57)                                                               1\n",
       "NACE 67 (67)                                                               1\n",
       "Name: count, Length: 84, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn[\"nace2_name_code\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "072a9053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nace2', 'row_id', 'age', 'tanass_clean', 'eszk', 'sales_clean',\n",
       "       'pretax', 'persexp_clean', 'satok', 'export_value', 'ereduzem', 'emp',\n",
       "       'liabilities', 'has_export', 'has_grant', 'exit', 'region', 'county',\n",
       "       'firm_owner', 'name_hu', 'nace2_name_code', 'ln_sales', 'growth_sim',\n",
       "       'ln_sales_lead_sim', 'sales_lead_sim', 'county_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969fe413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
